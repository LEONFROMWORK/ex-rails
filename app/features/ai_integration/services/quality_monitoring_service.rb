# frozen_string_literal: true

module AiIntegration
  module Services
    # AI ì‘ë‹µ í’ˆì§ˆì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ëŠ” ì„œë¹„ìŠ¤
    class QualityMonitoringService
      include Singleton

      METRIC_TYPES = {
        response_quality: "ai.response.quality",
        response_time: "ai.response.time",
        token_usage: "ai.token.usage",
        cost: "ai.cost",
        error_rate: "ai.error.rate",
        fallback_rate: "ai.fallback.rate",
        cache_hit_rate: "ai.cache.hit_rate",
        model_usage: "ai.model.usage",
        confidence_distribution: "ai.confidence.distribution"
      }.freeze

      QUALITY_THRESHOLDS = {
        critical: 0.5,
        warning: 0.65,
        good: 0.8,
        excellent: 0.9
      }.freeze

      def initialize
        @redis = Redis.new(url: ENV["REDIS_URL"] || "redis://localhost:6379")
        @metrics_buffer = []
        @buffer_mutex = Mutex.new
        @alert_cooldown = {}

        # ë°±ê·¸ë¼ìš´ë“œ í”ŒëŸ¬ì‹œ ì‹œì‘
        start_background_flush
      end

      # ë©”íŠ¸ë¦­ ê¸°ë¡
      def record_metric(type, value, tags = {})
        metric = {
          type: METRIC_TYPES[type] || type,
          value: value,
          tags: default_tags.merge(tags),
          timestamp: Time.current.to_f
        }

        @buffer_mutex.synchronize do
          @metrics_buffer << metric
        end

        # ì„ê³„ê°’ ì²´í¬
        check_thresholds(type, value, tags) if type == :response_quality

        # ë²„í¼ê°€ í¬ë©´ ì¦‰ì‹œ í”ŒëŸ¬ì‹œ
        flush_metrics if @metrics_buffer.size > 100
      end

      # AI ì‘ë‹µ ë¶„ì„ ë° ê¸°ë¡
      def analyze_response(response_data)
        analysis = {
          model: response_data[:model],
          tier: response_data[:tier],
          confidence: response_data[:confidence_score],
          processing_time: response_data[:processing_time],
          tokens_used: response_data[:credits_used],
          cost: response_data[:cost_breakdown][:current_cost],
          is_fallback: response_data[:is_fallback] || false,
          fallback_chain: response_data[:fallback_details],
          quality_metrics: response_data[:quality_metrics]
        }

        # ê°œë³„ ë©”íŠ¸ë¦­ ê¸°ë¡
        record_metric(:response_quality, analysis[:confidence],
                     model: analysis[:model], tier: analysis[:tier])

        record_metric(:response_time, analysis[:processing_time],
                     model: analysis[:model], tier: analysis[:tier])

        record_metric(:token_usage, analysis[:tokens_used],
                     model: analysis[:model])

        record_metric(:cost, analysis[:cost],
                     model: analysis[:model])

        # í´ë°± ë°œìƒì‹œ ì¶”ê°€ ë©”íŠ¸ë¦­
        if analysis[:is_fallback]
          record_metric(:fallback_rate, 1,
                       original_tier: analysis[:fallback_chain]&.first&.dig(:tier),
                       final_tier: analysis[:tier])
        end

        # ì‹¤ì‹œê°„ í†µê³„ ì—…ë°ì´íŠ¸
        update_realtime_stats(analysis)

        analysis
      end

      # ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œìš© í†µê³„
      def get_realtime_stats(window: 5.minutes)
        stats = {}

        # Redisì—ì„œ ìµœê·¼ í†µê³„ ê°€ì ¸ì˜¤ê¸°
        stats[:avg_quality] = get_windowed_average("quality", window)
        stats[:avg_response_time] = get_windowed_average("response_time", window)
        stats[:total_requests] = get_windowed_count("requests", window)
        stats[:error_rate] = get_windowed_rate("errors", window)
        stats[:fallback_rate] = get_windowed_rate("fallbacks", window)
        stats[:cache_hit_rate] = get_windowed_rate("cache_hits", window)

        # ëª¨ë¸ë³„ ì‚¬ìš©ëŸ‰
        stats[:model_distribution] = get_model_distribution(window)

        # í’ˆì§ˆ ë¶„í¬
        stats[:quality_distribution] = get_quality_distribution(window)

        # ë¹„ìš© í†µê³„
        stats[:cost_stats] = get_cost_statistics(window)

        # ì•Œë¦¼ ìƒíƒœ
        stats[:active_alerts] = get_active_alerts

        stats
      end

      # ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„±
      def generate_report(start_time, end_time)
        report = {
          period: {
            start: start_time,
            end: end_time,
            duration_hours: (end_time - start_time) / 3600.0
          },
          summary: generate_summary_stats(start_time, end_time),
          quality_analysis: analyze_quality_trends(start_time, end_time),
          performance_analysis: analyze_performance(start_time, end_time),
          cost_analysis: analyze_costs(start_time, end_time),
          recommendations: generate_recommendations(start_time, end_time)
        }

        # ë¦¬í¬íŠ¸ ì €ì¥
        save_report(report)

        report
      end

      # ì•Œë¦¼ ì„¤ì •
      def configure_alerts(config)
        @alert_config = config
      end

      private

      def start_background_flush
        Thread.new do
          loop do
            sleep 10
            flush_metrics
          rescue StandardError => e
            Rails.logger.error("Metric flush error: #{e.message}")
          end
        end
      end

      def flush_metrics
        metrics_to_flush = nil

        @buffer_mutex.synchronize do
          return if @metrics_buffer.empty?
          metrics_to_flush = @metrics_buffer.dup
          @metrics_buffer.clear
        end

        # ë©”íŠ¸ë¦­ ì €ì¥ (TimescaleDB, InfluxDB, ë˜ëŠ” Prometheus)
        store_metrics(metrics_to_flush)

        # Redisì— ì‹¤ì‹œê°„ í†µê³„ ì—…ë°ì´íŠ¸
        update_redis_stats(metrics_to_flush)
      end

      def store_metrics(metrics)
        # ë°°ì¹˜ ì‚½ì…ì„ ìœ„í•œ ê·¸ë£¹í™”
        grouped = metrics.group_by { |m| m[:type] }

        grouped.each do |type, type_metrics|
          # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (ì˜ˆ: TimescaleDB)
          AiMetric.insert_all(
            type_metrics.map do |metric|
              {
                metric_type: type,
                value: metric[:value],
                tags: metric[:tags].to_json,
                timestamp: Time.at(metric[:timestamp]),
                created_at: Time.current,
                updated_at: Time.current
              }
            end
          )
        end
      rescue StandardError => e
        Rails.logger.error("Failed to store metrics: #{e.message}")
      end

      def update_redis_stats(metrics)
        pipeline = @redis.pipelined do |pipe|
          metrics.each do |metric|
            key_prefix = "ai_metrics:#{metric[:type]}"

            # ì‹œê³„ì—´ ë°ì´í„° ì €ì¥ (1ì‹œê°„ ìœˆë„ìš°)
            window_key = "#{key_prefix}:#{Time.at(metric[:timestamp]).strftime('%Y%m%d%H')}"
            pipe.zadd(window_key, metric[:timestamp], metric[:value])
            pipe.expire(window_key, 25.hours)

            # ì§‘ê³„ í†µê³„ ì—…ë°ì´íŠ¸
            case metric[:type]
            when METRIC_TYPES[:response_quality]
              update_quality_stats(pipe, metric)
            when METRIC_TYPES[:response_time]
              update_performance_stats(pipe, metric)
            when METRIC_TYPES[:cost]
              update_cost_stats(pipe, metric)
            end
          end
        end
      end

      def update_quality_stats(pipe, metric)
        model = metric[:tags][:model]
        quality = metric[:value]

        # ì´ë™ í‰ê·  ì—…ë°ì´íŠ¸
        pipe.lpush("quality:#{model}:recent", quality)
        pipe.ltrim("quality:#{model}:recent", 0, 99)

        # í’ˆì§ˆ êµ¬ê°„ë³„ ì¹´ìš´í„°
        quality_tier = case quality
        when 0.9..1.0 then "excellent"
        when 0.8..0.9 then "good"
        when 0.65..0.8 then "acceptable"
        else "poor"
        end

        pipe.hincrby("quality:distribution:#{model}", quality_tier, 1)
      end

      def check_thresholds(type, value, tags)
        return unless @alert_config

        # í’ˆì§ˆì´ ì„ê³„ê°’ ì´í•˜ë¡œ ë–¨ì–´ì§„ ê²½ìš°
        if type == :response_quality && value < QUALITY_THRESHOLDS[:warning]
          trigger_alert(
            level: value < QUALITY_THRESHOLDS[:critical] ? :critical : :warning,
            message: "AI response quality below threshold: #{value.round(2)}",
            details: {
              model: tags[:model],
              tier: tags[:tier],
              threshold: QUALITY_THRESHOLDS[:warning]
            }
          )
        end
      end

      def trigger_alert(level:, message:, details: {})
        alert_key = "#{level}:#{message.parameterize}"

        # ì¿¨ë‹¤ìš´ ì²´í¬
        return if @alert_cooldown[alert_key] &&
                 Time.current - @alert_cooldown[alert_key] < 5.minutes

        @alert_cooldown[alert_key] = Time.current

        # ì•Œë¦¼ ì „ì†¡
        case level
        when :critical
          send_critical_alert(message, details)
        when :warning
          send_warning_alert(message, details)
        end

        # ì•Œë¦¼ ê¸°ë¡
        record_alert(level, message, details)
      end

      def send_critical_alert(message, details)
        # Slack, PagerDuty, ì´ë©”ì¼ ë“±
        Rails.logger.error("CRITICAL ALERT: #{message} - #{details.to_json}")

        # Slack ì›¹í›… (ì„¤ì •ëœ ê²½ìš°)
        if ENV["SLACK_WEBHOOK_URL"]
          notify_slack(
            channel: "#alerts-critical",
            message: "ğŸš¨ #{message}",
            details: details,
            color: "danger"
          )
        end
      end

      def get_windowed_average(metric, window)
        key = "ai_metrics:#{METRIC_TYPES["response_#{metric}".to_sym]}:#{Time.current.strftime('%Y%m%d%H')}"
        values = @redis.zrange(key, 0, -1)

        return 0 if values.empty?

        values.map(&:to_f).sum / values.size
      end

      def get_model_distribution(window)
        # ëª¨ë¸ë³„ ì‚¬ìš© íšŸìˆ˜ ì§‘ê³„
        distribution = {}

        OpenrouterMultimodalService::MULTIMODAL_MODELS.each do |tier, config|
          model = config[:model]
          count = @redis.get("model_usage:#{model}:#{Time.current.strftime('%Y%m%d%H')}").to_i
          distribution[tier] = {
            model: model,
            count: count,
            percentage: 0 # ë‚˜ì¤‘ì— ê³„ì‚°
          }
        end

        total = distribution.values.sum { |v| v[:count] }
        distribution.each do |tier, data|
          data[:percentage] = total > 0 ? (data[:count].to_f / total * 100).round(2) : 0
        end

        distribution
      end

      def generate_recommendations(start_time, end_time)
        recommendations = []

        # í’ˆì§ˆ ê¸°ë°˜ ì¶”ì²œ
        avg_quality = get_period_average("quality", start_time, end_time)
        if avg_quality < 0.7
          recommendations << {
            type: "quality",
            priority: "high",
            message: "í‰ê·  ì‘ë‹µ í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ìƒìœ„ í‹°ì–´ ëª¨ë¸ ì‚¬ìš©ì„ ê³ ë ¤í•˜ì„¸ìš”.",
            metric: avg_quality
          }
        end

        # ë¹„ìš© ê¸°ë°˜ ì¶”ì²œ
        cost_efficiency = calculate_cost_efficiency(start_time, end_time)
        if cost_efficiency < 0.6
          recommendations << {
            type: "cost",
            priority: "medium",
            message: "ë¹„ìš© íš¨ìœ¨ì„±ì´ ë‚®ìŠµë‹ˆë‹¤. ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„ê¸° ì¡°ì •ì„ ê¶Œì¥í•©ë‹ˆë‹¤.",
            metric: cost_efficiency
          }
        end

        # í´ë°± ë¹„ìœ¨ ê¸°ë°˜ ì¶”ì²œ
        fallback_rate = get_period_rate("fallbacks", start_time, end_time)
        if fallback_rate > 0.2
          recommendations << {
            type: "reliability",
            priority: "high",
            message: "í´ë°± ë¹„ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤. ì´ˆê¸° í‹°ì–´ ì„ íƒ ë¡œì§ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.",
            metric: fallback_rate
          }
        end

        recommendations
      end

      def default_tags
        {
          environment: Rails.env,
          app_version: Rails.application.config.app_version || "unknown",
          hostname: Socket.gethostname
        }
      end
    end
  end
end
